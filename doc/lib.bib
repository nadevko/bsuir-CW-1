@online{about-practice,
  title    = {БГУИР - Учебная практика},
  urldate  = {2024-05-16},
  url      = {https://www.bsuir.by/ru/kaf-ipie/uchebnaya-praktika},
  media    = {eresource},
  language = {russian}
}

@online{about-yandex,
  title    = {Чем занимается UX/UI-дизайнер или дизайнер интерфейсов},
  urldate  = {2024-05-16},
  url      = {https://practicum.yandex.ru/interface-designer/},
  media    = {eresource},
  language = {russian}
}

@online{majors,
  title    = {
              30 профессиональных ролей ИКТ специалистов на основе Европейской
              системы электронных компетенций (стандарт e-CF EN 16234-1)
              (неофициальный сокращенный перевод)
              },
  urldate  = {2024-05-16},
  url      = {https://docs.google.com/document/d/1w9ClM7Ha9K03LXSGi2DN0ruKp2zAIIs5Jt32yzSvplg},
  media    = {eresource},
  language = {russian}
}

@online{devops-mts,
  title    = {
              DevOps «по полочкам»: задачи, скиллы, перспективы, плюсы и минусы
              профессии 
              },
  urldate  = {2024-05-16},
  url      = {https://vc.ru/mts/491840-devops-po-polochkam-zadachi-skilly-perspektivy-plyusy-i-minusy-professii},
  media    = {eresource},
  language = {russian}
}

@online{devops-habr,
  title    = {Зарплаты в IT по всем IT-специальностям},
  urldate  = {2024-05-16},
  url      = {https://career.habr.com/salaries},
  media    = {eresource},
  language = {russian}
}

@misc{simonyan2015deep,
  title         = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author        = {Karen Simonyan and Andrew Zisserman},
  year          = {2015},
  eprint        = {1409.1556},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV}
}

@inproceedings{Koch2015SiameseNN,
  title  = {Siamese Neural Networks for One-Shot Image Recognition},
  author = {Gregory R. Koch},
  year   = {2015},
  url    = {https://api.semanticscholar.org/CorpusID:13874643}
}

@article{DBLP:journals/corr/abs-2002-05709,
  author     = {Ting Chen and
                Simon Kornblith and
                Mohammad Norouzi and
                Geoffrey E. Hinton},
  title      = {A Simple Framework for Contrastive Learning of Visual Representations},
  journal    = {CoRR},
  volume     = {abs/2002.05709},
  year       = {2020},
  url        = {https://arxiv.org/abs/2002.05709},
  eprinttype = {arXiv},
  eprint     = {2002.05709},
  timestamp  = {Fri, 14 Feb 2020 12:07:41 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2002-05709.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{10.1007/978-3-319-24574-4_28,
  author    = {Ronneberger, Olaf
               and Fischer, Philipp
               and Brox, Thomas},
  editor    = {Navab, Nassir
               and Hornegger, Joachim
               and Wells, William M.
               and Frangi, Alejandro F.},
  title     = {U-Net: Convolutional Networks for Biomedical Image Segmentation},
  booktitle = {Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015},
  year      = {2015},
  publisher = {Springer International Publishing},
  address   = {Cham},
  pages     = {234--241},
  abstract  = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.},
  isbn      = {978-3-319-24574-4}
}

@article{radford2015unsupervised,
  title   = {Unsupervised representation learning with deep convolutional generative adversarial networks},
  author  = {Radford, Alec and Metz, Luke and Chintala, Soumith},
  journal = {arXiv preprint arXiv:1511.06434},
  year    = {2015}
}

@article{ali2016survey,
  title   = {A survey of similarity measures in web image search},
  author  = {Ali, Yossra H and Abdullah, Wathiq N},
  journal = {International Journal of Emerging Trends Technology in Computer Science},
  volume  = {4},
  number  = {4},
  year    = {2016}
}

@article{астафьева1996вейвлет,
  title    = {Вейвлет-анализ: основы теории и примеры применения},
  author   = {Астафьева, Наталья Михайловна},
  journal  = {Успехи физических наук},
  volume   = {166},
  number   = {11},
  pages    = {1145--1170},
  year     = {1996},
  language = {russian}
}

@article{lowe2004distinctive,
  title     = {Distinctive image features from scale-invariant keypoints},
  author    = {Lowe, David G},
  journal   = {International journal of computer vision},
  volume    = {60},
  pages     = {91--110},
  year      = {2004},
  publisher = {Springer}
}

@article{wang2004image,
  title     = {Image quality assessment: from error visibility to structural similarity},
  author    = {Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal   = {IEEE transactions on image processing},
  volume    = {13},
  number    = {4},
  pages     = {600--612},
  year      = {2004},
  publisher = {IEEE}
}

@article{zauner2010implementation,
  title     = {Implementation and benchmarking of perceptual image hash functions},
  author    = {Zauner, Christoph},
  year      = {2010},
  publisher = {na}
}

@online{benchmarks-odiff,
  title   = {dmtrKovalenko/odiff: The fastest pixel-by-pixel image visual difference tool in the world.},
  urldate = {2024-05-16},
  url     = {https://github.com/dmtrKovalenko/odiff\#benchmarks},
  media   = {eresource}
}

@misc{xdg_base_directory_spec,
  title   = {XDG Base Directory Specification},
  author  = {Waldo Bastian and Allison Karlitskaya and Lennart Poettering and Johannes Löthberg},
  year    = {2021},
  month   = {May},
  day     = {08},
  version = {0.8},
  email   = {bastian@kde.org and desrt@desrt.ca and lennart@poettering.net and johannes@kyriasis.com},
  url     = {https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html},
  urldate = {2024-05-16}
}
